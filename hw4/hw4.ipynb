{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Assignment 4**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **ECON8502: Structural Microeconometrics**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Conor Bayliss*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Setup**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This week you will estimate a simple hidden Markov model using Expectation-Maximisation.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Here is the model. There is a discrete state variable $k\\in\\{1,2,3,...,K\\}$ and a binary outcome $j\\in\\{0,1\\}$ that:*\n",
    "1. *Is determined probabilistically by the state; and*\n",
    "2. *Moves the state up one grid point if $j=1$, i.e. $k_{t+1} = \\min\\{K,k_{t+j}\\}$*\n",
    "\n",
    "*Let $p$ be a K-dimensional vector where $p_k$ holds the probability that $j=1$ given that the model is in state $k$.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The state $k$ is never observed and the outcome $j$ is only observed half the time (i.e. it is missing with probability 0.5). Thus, define $j^{*}$ to be:*\n",
    "$$\n",
    "j^* = \n",
    "\\begin{cases} \n",
    "j & \\text{with probability } 0.5 \\\\\n",
    "-1 & \\text{with probability } 0.5\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Our task is to estimate the vector of outcome probabilities $p$ non-parametrically using the EM algorithm with the Forward-Back routine to calculate the E-step*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The code below calcualtes $p$ and simulates panel data*\n",
    "$$\n",
    "(j^*_{nt})_{t=1,n=1}^{T,N}\n",
    "$$\n",
    "*To start with, assume $k_{n,1} = 1, \\forall n$.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pj = [0.7310585786300049, 0.6224593312018546, 0.5, 0.3775406687981454, 0.2689414213699951]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10×1000 Matrix{Float64}:\n",
       "  1.0  -1.0   0.0   1.0   0.0   1.0  …  -1.0   1.0   1.0  -1.0  -1.0  -1.0\n",
       " -1.0   1.0  -1.0   1.0   0.0  -1.0      0.0  -1.0  -1.0  -1.0   1.0  -1.0\n",
       " -1.0   0.0   1.0   0.0   0.0  -1.0      1.0   1.0  -1.0   1.0  -1.0   0.0\n",
       " -1.0   0.0  -1.0  -1.0  -1.0   0.0     -1.0  -1.0   1.0   1.0   0.0  -1.0\n",
       " -1.0  -1.0   0.0  -1.0  -1.0  -1.0      1.0  -1.0  -1.0   0.0   0.0  -1.0\n",
       "  1.0  -1.0  -1.0  -1.0  -1.0  -1.0  …  -1.0   0.0  -1.0   0.0   1.0  -1.0\n",
       " -1.0   1.0   1.0   0.0   0.0  -1.0     -1.0  -1.0   0.0   1.0   0.0   0.0\n",
       " -1.0   1.0  -1.0   1.0   0.0  -1.0     -1.0   0.0   0.0   0.0   0.0   0.0\n",
       " -1.0  -1.0  -1.0   0.0   1.0  -1.0     -1.0  -1.0  -1.0   0.0  -1.0   0.0\n",
       " -1.0  -1.0   0.0   0.0  -1.0   1.0     -1.0   0.0  -1.0  -1.0  -1.0   0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using Random, Distributions\n",
    "K = 5\n",
    "Pj = 1 ./ (1 .+ exp.(LinRange(-1,1,K))) #<- choice probability as a function of k\n",
    "@show Pj\n",
    "knext(k,j,K) = min(K,k+j) \n",
    "\n",
    "function simulate(N,T,Pj)\n",
    "    J = zeros(T,N)\n",
    "    K = length(Pj)\n",
    "    for n in axes(J,2)\n",
    "        k = 1\n",
    "        for t in axes(J,1)\n",
    "            j = rand()<Pj[k]\n",
    "            # record j probabilistically\n",
    "            if rand()<0.5\n",
    "                J[t,n] = -1\n",
    "            else\n",
    "                J[t,n] = j\n",
    "            end\n",
    "            # update state:\n",
    "            k = knext(k,j,K)\n",
    "        end\n",
    "    end\n",
    "    return J\n",
    "end\n",
    "\n",
    "J_data = simulate(1000,10,Pj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Since the outcomes $j$ are peridoically unobserved, there are two ways to set up the EM problem:*\n",
    "1. *Define a composite state variable $s=(k,j)$ that is partially unobserved and define $\\alpha$ and $\\beta$ over this composite state*\n",
    "2. *Define $\\alpha$ and $\\beta$ over $k$ only and sum over potential realisations of $j$ when missing*.\n",
    "\n",
    "*When the number of discrete outcomes is larger, it becomes more difficult to integrate them out when missing. Since $j$ is binary, we will use the second approach.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Part 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write a function that (given a guess of the parameters $p$) takes a sequence of $(j^*)_{t=1}^T$ and runs the forward-back algorithm. In doing so, your function should fill in three objects:*\n",
    "1. *A $K$ x $T$ array of backward looking probabilities $(\\alpha)$*\n",
    "2. *A $K$ x $T$ array of forward looking probabilities $(\\beta)$*\n",
    "3. *A $K$ x $T$ array of posterior probabilities over each state $k(Q)$*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Recall that*\n",
    "$$\n",
    "\\alpha[k,s] = \\mathbb{P}[k_s=k,(j^*)_{t=1}^s]\n",
    "$$\n",
    "$$\n",
    "\\beta[k,s] = \\mathbb{P}[(j^*)_{t=s+1}^T|k_s=k]\n",
    "$$\n",
    "and\n",
    "$$\n",
    "Q[k,s] = \\mathbb{P}[k_s=k|(j^*)_{t=1}^T]\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.5 0.0 … 0.0 0.0; 0.5 0.5 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 1.0 1.0], [3.814697265625e-6 7.62939453125e-6 … 0.0625 0.25; 3.814697265625e-6 7.62939453125e-6 … 0.0625 0.25; … ; 3.814697265625e-6 7.62939453125e-6 … 0.0625 0.25; 3.814697265625e-6 7.62939453125e-6 … 0.0625 0.25], [1.0 0.5 … 0.0 0.0; 0.0 0.5 … 0.0 0.0; … ; 0.0 0.0 … 0.25 0.0; 0.0 0.0 … 0.75 1.0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using LinearAlgebra\n",
    "P_guess = zeros(K,1) \n",
    "P_guess .= 0.5\n",
    "α_init = zeros(K,1)\n",
    "α_init[1] = 1\n",
    "β_end = ones(K,1)\n",
    "\n",
    "############################################################################################################\n",
    "\n",
    "function fb(P_guess, J_data, n , α_init, β_end)\n",
    "    T,N = size(J_data)\n",
    "    K = length(P_guess)\n",
    "    α, β = zeros(K,T+1), zeros(K,T+1)\n",
    "    α[:,1] .= α_init\n",
    "    β[:,T+1] .= β_end\n",
    "    Q = zeros(K,T)\n",
    "    #############################\n",
    "    for j in 1:1\n",
    "        if j == 1\n",
    "            if J_data[j,n] == 0\n",
    "                α[:,2] .= α[:,1]\n",
    "            elseif J_data[j,n] == 1\n",
    "                α[2:K,2] .= α[1:K-1,1]\n",
    "                α[K,2] += α[K,1]\n",
    "            elseif J_data[j,n] == -1\n",
    "                α[1,2] = α[1,1] * (1 - P_guess[1])\n",
    "                α[2,2] = α[1,1] * P_guess[1]\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    for j in 2:T\n",
    "        if J_data[j,n] == 0\n",
    "            α[:,j+1] .= α[:,j]\n",
    "        elseif J_data[j,n] == 1\n",
    "            α[2:K,j+1] = α[1:K-1,j]\n",
    "            α[K,j+1] += α[K,j] \n",
    "        elseif J_data[j,n] == -1\n",
    "            α_temp_0 = zeros(K,1)\n",
    "            α_temp_1 = zeros(K,1)\n",
    "            α_temp_0[1:K-1] = α[1:K-1,j] .* (1 .- P_guess[1:K-1])\n",
    "            α_temp_1[2:K] = α[1:K-1,j] .* P_guess[1:K-1]\n",
    "            α_temp_1[K] += α[K,j]\n",
    "            α[:,j+1] = α_temp_0 .+ α_temp_1\n",
    "        end\n",
    "    end\n",
    "    #############################\n",
    "    for j in reverse(1:T)\n",
    "        j_today = J_data[j,n]\n",
    "        if j_today == -1 \n",
    "            β[:,j] .= 0.5 .* β[:,j+1]\n",
    "        elseif j_today == 0 \n",
    "            β[:,j] .= 0.25 .* β[:,j+1]\n",
    "        elseif j_today == 1 \n",
    "            β[:,j] .= 0.25 .* β[:,j+1]\n",
    "        end\n",
    "    end\n",
    "    ###############################\n",
    "    for t in 1:T\n",
    "        Q[:,t] = α[:,t] .* β[:,t]\n",
    "        Q[:,t] = Q[:,t] ./ sum(Q[:,t])\n",
    "    end\n",
    "    ###############################\n",
    "    return α[:, end-9:end], β[:, 1:10], Q\n",
    "end\n",
    "\n",
    "############################################################################################################\n",
    "\n",
    "ex_α, ex_β, Q = fb(P_guess,J_data,735,α_init,β_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Part 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write a function that iterates over all observations and calculates posterior state probabilities for every observation. i.e. fill in a $K$ x $T$ x $N$ array of posterior weights.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.0 0.0 … 0.0 0.0; 1.0 0.5 … 0.0 0.0; … ; 0.0 0.0 … 0.0546875 0.03125; 0.0 0.0 … 0.9375 0.96484375;;; 0.5 0.0 … 0.0 0.0; 0.5 0.5 … 0.0 0.0; … ; 0.0 0.0 … 0.0625 0.03125; 0.0 0.0 … 0.9375 0.96875;;; 1.0 0.5 … 0.0 0.0; 0.0 0.5 … 0.0 0.0; … ; 0.0 0.0 … 0.15625 0.15625; 0.0 0.0 … 0.8125 0.8125;;; … ;;; 0.5 0.25 … 0.0 0.0; 0.5 0.5 … 0.0 0.0; … ; 0.0 0.0 … 0.25 0.125; 0.0 0.0 … 0.75 0.875;;; 0.5 0.0 … 0.0 0.0; 0.5 0.5 … 0.0 0.0; … ; 0.0 0.0 … 0.375 0.25; 0.0 0.0 … 0.5 0.6875;;; 0.5 0.25 … 0.03125 0.03125; 0.5 0.5 … 0.15625 0.15625; … ; 0.0 0.0 … 0.3125 0.3125; 0.0 0.0 … 0.1875 0.1875], [0.000244140625 0.0009765625 … 0.25 0.5; 0.000244140625 0.0009765625 … 0.25 0.5; … ; 0.000244140625 0.0009765625 … 0.25 0.5; 0.000244140625 0.0009765625 … 0.25 0.5;;; 3.0517578125e-5 6.103515625e-5 … 0.25 0.5; 3.0517578125e-5 6.103515625e-5 … 0.25 0.5; … ; 3.0517578125e-5 6.103515625e-5 … 0.25 0.5; 3.0517578125e-5 6.103515625e-5 … 0.25 0.5;;; 3.0517578125e-5 0.0001220703125 … 0.125 0.25; 3.0517578125e-5 0.0001220703125 … 0.125 0.25; … ; 3.0517578125e-5 0.0001220703125 … 0.125 0.25; 3.0517578125e-5 0.0001220703125 … 0.125 0.25;;; … ;;; 7.62939453125e-6 1.52587890625e-5 … 0.125 0.5; 7.62939453125e-6 1.52587890625e-5 … 0.125 0.5; … ; 7.62939453125e-6 1.52587890625e-5 … 0.125 0.5; 7.62939453125e-6 1.52587890625e-5 … 0.125 0.5;;; 1.52587890625e-5 3.0517578125e-5 … 0.25 0.5; 1.52587890625e-5 3.0517578125e-5 … 0.25 0.5; … ; 1.52587890625e-5 3.0517578125e-5 … 0.25 0.5; 1.52587890625e-5 3.0517578125e-5 … 0.25 0.5;;; 3.0517578125e-5 6.103515625e-5 … 0.0625 0.25; 3.0517578125e-5 6.103515625e-5 … 0.0625 0.25; … ; 3.0517578125e-5 6.103515625e-5 … 0.0625 0.25; 3.0517578125e-5 6.103515625e-5 … 0.0625 0.25], [1.0 1.0 … 1.0 1.0; 0.0 0.0 … 0.0 0.0; … ; 0.2734375 0.15625 … 0.1640625 0.25; 0.5 0.8125 … 0.7734375 0.6875;;; 1.0 1.0 … 1.0 1.0; 0.0 0.0 … 0.0 0.0; … ; 0.5 0.375 … 0.03125 0.375; 0.5 0.3125 … 0.96875 0.3125;;; 1.0 1.0 … 1.0 1.0; 0.0 0.0 … 0.0 0.0; … ; 0.15625 0.15625 … 0.15625 0.15625; 0.8125 0.8125 … 0.8125 0.8125;;; 1.0 1.0 … 1.0 1.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.15625 … 0.09375 0.25; 1.0 0.8125 … 0.890625 0.6875;;; 1.0 1.0 … 1.0 1.0; 0.0 0.0 … 0.0 0.0; … ; 0.125 0.0 … 0.5 0.3125; 0.875 1.0 … 0.25 0.1875])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "α_obs = zeros(K,10,1000)\n",
    "β_obs = zeros(K,10,1000)\n",
    "Q_obs = zeros(K,10,1000)\n",
    "function iterate(α_obs, β_obs, Q_obs, P_guess, J_data, α_init, β_end)\n",
    "    for n in 1:1000\n",
    "        α_obs[:,:,n], β_obs[:,:,n], Q_obs[:,:,n] = fb(P_guess, J_data, n, α_init, β_end)\n",
    "    end\n",
    "    Q_obs = reshape(Q_obs, (1000,10,5))\n",
    "    return α_obs, β_obs, Q_obs\n",
    "end\n",
    "\n",
    "α_out, β_out, Q_out = iterate(α_obs, β_obs, Q_obs, P_guess, J_data, α_init, β_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Part 3**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Take as given a set of posterior weights $q_{ntk}=Q[n,t,k]$. The expected log-likelihood for the M-step is:*\n",
    "$$\n",
    "\\mathcal{L}(p) = \\sum_n \\sum_t \\sum_k q_{ntk}(\\mathbf{1}\\{j^*_{nt}=1\\}\\log(p_k)+\\mathbf{1}\\{j^*_{nt}=0\\}\\log(1-p_k))\n",
    "$$\n",
    "*Show that the non-parametric maximum likelihood estimate of $p$ given the posterior weights is a frequency estimator:*\n",
    "$$\n",
    "\\hat{p_k} = \\frac{\\sum_n \\sum_t \\mathbf{1}\\{j^*_{nt}=1\\}q_{ntk}}{\\sum_n \\sum_t \\mathbf{1}\\{j^*_{nt}\\neq-1\\}q_{ntk}}\n",
    "$$\n",
    "*Write a function to calculate this frequency estimator given posterior weights.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Excessive output truncated after 555853 bytes."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_out = "
     ]
    },
    {
     "data": {
      "text/plain": [
       "5×1 Matrix{Float64}:\n",
       " 0.45929093569107166\n",
       " 0.45858291657753636\n",
       " 0.4608807322163486\n",
       " 0.4591187619610585\n",
       " 0.4614067884963309"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function probs(α_obs, β_obs, Q_obs, P_guess, J_data, α_init, β_end)\n",
    "    j_observed_1 = zeros(10,1000)\n",
    "    j_observed_1 .= J_data .== 1\n",
    "    j_observed = zeros(10,1000)\n",
    "    j_observed .= J_data .!= -1\n",
    "    Q_out = iterate(α_obs, β_obs, Q_obs, P_guess, J_data, α_init, β_end)[3]\n",
    "    for k in 1:K\n",
    "        Q = Q_out[:,:,k]\n",
    "        num = j_observed_1 * Q\n",
    "        den = j_observed * Q\n",
    "        P_guess[k] = sum(sum(num, dims = 1), dims = 2)[] ./ sum(sum(den, dims = 1), dims = 2)[]\n",
    "    end\n",
    "    return P_guess\n",
    "end\n",
    "\n",
    "out = probs(α_obs, β_obs, Q_obs, P_guess, J_data, α_init, β_end)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Part 4**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Run the E-M routine by iterating on this E-step and M-step until you get convergence in $\\hat{p}$. Does it look like you can recover the true parameters?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EM (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function EM(J_data, α_init, β_end, toler, max_iter)\n",
    "    P_init = zeros(K,1)\n",
    "    P_init .= 0.9\n",
    "    error = 1+toler\n",
    "    iter = 0\n",
    "    α_iter = zeros(K,10,1000)\n",
    "    β_iter = zeros(K,10,1000)\n",
    "    Q_iter = zeros(K,10,1000)\n",
    "    while error > toler && iter < max_iter\n",
    "        @show iter\n",
    "        α_iter, β_iter, Q_iter = iterate(α_iter, β_iter, Q_iter, P_init, J_data, α_init, β_end)\n",
    "        #@show α_iter[:,:,735] #### works here ####\n",
    "        P_update = probs(α_iter, β_iter, Q_iter, P_init, J_data, α_init, β_end)\n",
    "        @show P_update\n",
    "        iter += 1\n",
    "        @show iter\n",
    "        error = maximum(abs.(P_update - P_init))\n",
    "        @show error\n",
    "        P_init = copy(P_update)\n",
    "    end\n",
    "    return P_init\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "DimensionMismatch",
     "evalue": "DimensionMismatch: tried to assign 5×10 array to 1000×10×1 destination",
     "output_type": "error",
     "traceback": [
      "DimensionMismatch: tried to assign 5×10 array to 1000×10×1 destination\n",
      "\n",
      "Stacktrace:\n",
      "  [1] throw_setindex_mismatch(X::Matrix{Float64}, I::Tuple{Int64, Int64, Int64})\n",
      "    @ Base .\\indices.jl:193\n",
      "  [2] setindex_shape_check(::Matrix{Float64}, ::Int64, ::Int64, ::Int64)\n",
      "    @ Base .\\indices.jl:231\n",
      "  [3] macro expansion\n",
      "    @ .\\multidimensional.jl:953 [inlined]\n",
      "  [4] _unsafe_setindex!(::IndexLinear, ::Array{Float64, 3}, ::Matrix{Float64}, ::Base.Slice{Base.OneTo{Int64}}, ::Base.Slice{Base.OneTo{Int64}}, ::Int64)\n",
      "    @ Base .\\multidimensional.jl:967\n",
      "  [5] _setindex!\n",
      "    @ .\\multidimensional.jl:944 [inlined]\n",
      "  [6] setindex!\n",
      "    @ .\\abstractarray.jl:1396 [inlined]\n",
      "  [7] iterate(α_obs::Array{Float64, 3}, β_obs::Array{Float64, 3}, Q_obs::Array{Float64, 3}, P_guess::Matrix{Float64}, J_data::Matrix{Float64}, α_init::Matrix{Float64}, β_end::Matrix{Float64})\n",
      "    @ Main c:\\Users\\bayle\\Documents\\Github\\micro_labour\\hw4\\hw4.ipynb:6\n",
      "  [8] probs(α_obs::Array{Float64, 3}, β_obs::Array{Float64, 3}, Q_obs::Array{Float64, 3}, P_guess::Matrix{Float64}, J_data::Matrix{Float64}, α_init::Matrix{Float64}, β_end::Matrix{Float64})\n",
      "    @ Main c:\\Users\\bayle\\Documents\\Github\\micro_labour\\hw4\\hw4.ipynb:6\n",
      "  [9] EM(J_data::Matrix{Float64}, α_init::Matrix{Float64}, β_end::Matrix{Float64}, toler::Float64, max_iter::Int64)\n",
      "    @ Main c:\\Users\\bayle\\Documents\\Github\\micro_labour\\hw4\\hw4.ipynb:13\n",
      " [10] top-level scope\n",
      "    @ c:\\Users\\bayle\\Documents\\Github\\micro_labour\\hw4\\hw4.ipynb:1"
     ]
    }
   ],
   "source": [
    "P_output = EM(J_data, α_init, β_end, 0.0001, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.1",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
