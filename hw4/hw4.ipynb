{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Assignment 4**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **ECON8502: Structural Microeconometrics**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Conor Bayliss*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Setup**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This week you will estimate a simple hidden Markov model using Expectation-Maximisation.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Here is the model. There is a discrete state variable $k\\in\\{1,2,3,...,K\\}$ and a binary outcome $j\\in\\{0,1\\}$ that:*\n",
    "1. *Is determined probabilistically by the state; and*\n",
    "2. *Moves the state up one grid point if $j=1$, i.e. $k_{t+1} = \\min\\{K,k_{t+j}\\}$*\n",
    "\n",
    "*Let $p$ be a K-dimensional vector where $p_k$ holds the probability that $j=1$ given that the model is in state $k$.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The state $k$ is never observed and the outcome $j$ is only observed half the time (i.e. it is missing with probability 0.5). Thus, define $j^{*}$ to be:*\n",
    "$$\n",
    "j^* = \n",
    "\\begin{cases} \n",
    "j & \\text{with probability } 0.5 \\\\\n",
    "-1 & \\text{with probability } 0.5\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Our task is to estimate the vector of outcome probabilities $p$ non-parametrically using the EM algorithm with the Forward-Back routine to calculate the E-step*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The code below calcualtes $p$ and simulates panel data*\n",
    "$$\n",
    "(j^*_{nt})_{t=1,n=1}^{T,N}\n",
    "$$\n",
    "*To start with, assume $k_{n,1} = 1, \\forall n$.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Vector{Float64}:\n",
       " -1.0\n",
       "  1.0\n",
       " -1.0\n",
       " -1.0\n",
       " -1.0\n",
       " -1.0\n",
       " -1.0\n",
       " -1.0\n",
       " -1.0\n",
       " -1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using Random, Distributions\n",
    "K = 5\n",
    "Pj = 1 ./ (1 .+ exp.(LinRange(-1,1,K))) #<- choice probability as a function of k\n",
    "knext(k,j,K) = min(K,k+j) \n",
    "\n",
    "function simulate(N,T,Pj)\n",
    "    J = zeros(T,N)\n",
    "    K = length(Pj)\n",
    "    for n in axes(J,2)\n",
    "        k = 1\n",
    "        for t in axes(J,1)\n",
    "            j = rand()<Pj[k]\n",
    "            # record j probabilistically\n",
    "            if rand()<0.5\n",
    "                J[t,n] = -1\n",
    "            else\n",
    "                J[t,n] = j\n",
    "            end\n",
    "            # update state:\n",
    "            k = knext(k,j,K)\n",
    "        end\n",
    "    end\n",
    "    return J\n",
    "end\n",
    "\n",
    "J_data = simulate(1000,10,Pj)\n",
    "J_data[:,735]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Since the outcomes $j$ are peridoically unobserved, there are two ways to set up the EM problem:*\n",
    "1. *Define a composite state variable $s=(k,j)$ that is partially unobserved and define $\\alpha$ and $\\beta$ over this composite state*\n",
    "2. *Define $\\alpha$ and $\\beta$ over $k$ only and sum over potential realisations of $j$ when missing*.\n",
    "\n",
    "*When the number of discrete outcomes is larger, it becomes more difficult to integrate them out when missing. Since $j$ is binary, we will use the second approach.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Part 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write a function that (given a guess of the parameters $p$) takes a sequence of $(j^*)_{t=1}^T$ and runs the forward-back algorithm. In doing so, your function should fill in three objects:*\n",
    "1. *A $K$ x $T$ array of backward looking probabilities $(\\alpha)$*\n",
    "2. *A $K$ x $T$ array of forward looking probabilities $(\\beta)$*\n",
    "3. *A $K$ x $T$ array of posterior probabilities over each state $k(Q)$*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Recall that*\n",
    "$$\n",
    "\\alpha[k,s] = \\mathbb{P}[k_s=k,(j^*)_{t=1}^s]\n",
    "$$\n",
    "$$\n",
    "\\beta[k,s] = \\mathbb{P}[(j^*)_{t=s+1}^T|k_s=k]\n",
    "$$\n",
    "and\n",
    "$$\n",
    "Q[k,s] = \\mathbb{P}[k_s=k|(j^*)_{t=1}^T]\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5×1 Matrix{Float64}:\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using LinearAlgebra\n",
    "P_guess = zeros(K,1) \n",
    "P_guess .= 0.5\n",
    "α_init = zeros(K,1)\n",
    "α_init[1] = 1\n",
    "β_end = ones(K,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5×10 Matrix{Float64}:\n",
       " 0.0  0.0  0.0   0.0    0.0     0.0     0.0      0.0      0.0      0.0\n",
       " 1.0  0.5  0.0   0.0    0.0     0.0     0.0      0.0      0.0      0.0\n",
       " 0.0  0.5  0.25  0.125  0.0     0.0     0.0      0.0      0.0      0.0\n",
       " 0.0  0.0  0.25  0.25   0.0625  0.0625  0.0      0.0      0.0      0.0\n",
       " 0.0  0.0  0.0   0.125  0.25    0.25    0.28125  0.28125  0.28125  0.28125"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function fb3(P_guess, J_data, n , α_init, β_end)\n",
    "    T,N = size(J_data)\n",
    "    K = length(P_guess)\n",
    "    α, β = zeros(K,T+1), zeros(K,T+1)\n",
    "    α[:,1] .= α_init\n",
    "    β[:,T+1] .= β_end\n",
    "    Q = zeros(K,T)\n",
    "    for j in 1:T\n",
    "        if j == 1\n",
    "            for k in 1:K\n",
    "                if J_data[j,n] == 0\n",
    "                    α[k,2] = α[k,1]\n",
    "                elseif J_data[j,n] == 1\n",
    "                    if k != K\n",
    "                        α[k+1,2] = α[k,1]\n",
    "                    elseif k == K\n",
    "                        α[k,2] = α[k,1]\n",
    "                    end\n",
    "                elseif J_data[j,n] == -1\n",
    "                    if k == 1\n",
    "                        α[k,2] = α[k,1] .* (1 .- P_guess[k])\n",
    "                        α[k+1,2] = α[k,1] .* P_guess[k]\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "        elseif j > 1\n",
    "            for k in 1:K\n",
    "                if J_data[j,n] == 0\n",
    "                    α[k,j+1] = α[k,j]\n",
    "                elseif J_data[j,n] == 1\n",
    "                    if k != K\n",
    "                        α[k+1,j+1] = α[k,j] .* P_guess[k]\n",
    "                    elseif k == K\n",
    "                        α[k,j+1] = α[k,j] .+ α[k-1,j] .* P_guess[k-1]\n",
    "                    end\n",
    "                elseif J_data[j,n] == -1\n",
    "                    if k == 1\n",
    "                        α[k,j+1] = α[k,j] .* (1 .- P_guess[k]) \n",
    "                        α[k+1,j+1] = α[k,j] .* P_guess[k] \n",
    "                    elseif k < K\n",
    "                        α[k,j+1] = α[k,j] .* (1 .- P_guess[k]) .+ α[k-1,j] .* P_guess[k-1]\n",
    "                        α[k+1,j+1] = α[k,j] .* P_guess[k]\n",
    "                    elseif k == K\n",
    "                        α[k,j+1] = α[k,j] .+ α[k-1,j] .* P_guess[k-1]\n",
    "                    end \n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return α[:, end-9:end]\n",
    "end\n",
    "\n",
    "ex3 = fb3(P_guess,J_data,371,α_init,β_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5×10 Matrix{Float64}:\n",
       " 0.5  0.0  0.0   0.0    0.0     0.0      …  0.0        0.0         0.0\n",
       " 0.5  0.5  0.25  0.125  0.0625  0.03125     0.0078125  0.00390625  0.00195312\n",
       " 0.0  0.5  0.5   0.375  0.25    0.15625     0.0546875  0.03125     0.0175781\n",
       " 0.0  0.0  0.25  0.375  0.375   0.3125      0.164062   0.109375    0.0703125\n",
       " 0.0  0.0  0.0   0.125  0.3125  0.5         0.773438   0.855469    0.910156"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function fb4(P_guess, J_data, n , α_init, β_end)\n",
    "    T,N = size(J_data)\n",
    "    K = length(P_guess)\n",
    "    α, β = zeros(K,T+1), zeros(K,T+1)\n",
    "    α[:,1] .= α_init\n",
    "    β[:,T+1] .= β_end\n",
    "    Q = zeros(K,T)\n",
    "\n",
    "    for j in 1:T\n",
    "        if j == 1\n",
    "            if J_data[j,n] == 0\n",
    "                α[:,2] .= α[:,1]\n",
    "            elseif J_data[j,n] == 1\n",
    "                α[2:K,2] .= α[1:K-1,1]\n",
    "                α[K,2] += α[K,1]\n",
    "            elseif J_data[j,n] == -1\n",
    "                α[1,2] = α[1,1] * (1 - P_guess[1])\n",
    "                α[2,2] = α[1,1] * P_guess[1]\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "        for j in 2:T\n",
    "            if J_data[j,n] == 0\n",
    "                α[:,j+1] .= α[:,j]\n",
    "            elseif J_data[j,n] == 1\n",
    "                α[2:K,j+1] = α[1:K-1,j]\n",
    "                α[K,j+1] += α[K,j] \n",
    "            elseif J_data[j,n] == -1\n",
    "                α_temp_0 = zeros(K,1)\n",
    "                α_temp_1 = zeros(K,1)\n",
    "                α_temp_0[1:K-1] = α[1:K-1,j] .* (1 .- P_guess[1:K-1])\n",
    "                α_temp_1[2:K] = α[1:K-1,j] .* P_guess[1:K-1]\n",
    "                α_temp_1[K] += α[K,j]\n",
    "                α[:,j+1] = α_temp_0 .+ α_temp_1\n",
    "            end\n",
    "        end\n",
    "    \n",
    "    return α[:, end-9:end]\n",
    "end\n",
    "\n",
    "ex4 = fb4(P_guess,J_data,735,α_init,β_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Part 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write a function that iterates over all observations and calculates posterior state probabilities for every observation. i.e. fill in a $K$ x $T$ x $N$ array of posterior weights.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Part 3**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Take as given a set of posterior weights $q_{ntk}=Q[n,t,k]$. The expected log-likelihood for the M-step is:*\n",
    "$$\n",
    "\\mathcal{L}(p) = \\sum_n \\sum_t \\sum_k q_{ntk}(\\mathbf{1}\\{j^*_{nt}=1\\}\\log(p_k)+\\mathbf{1}\\{j^*_{nt}=0\\}\\log(1-p_k))\n",
    "$$\n",
    "*Show that the non-parametric maximum likelihood estimate of $p$ given the posterior weights is a frequency estimator:*\n",
    "$$\n",
    "\\hat{p_k} = \\frac{\\sum_n \\sum_t \\mathbf{1}\\{j^*_{nt}=1\\}q_{ntk}}{\\sum_n \\sum_t \\mathbf{1}\\{j^*_{nt}\\neq-1\\}q_{ntk}}\n",
    "$$\n",
    "*Write a function to calculate this frequency estimator given posterior weights.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Part 4**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Run the E-M routine by iterating on this E-step and M-step until you get convergence in $\\hat{p}$. Does it look like you can recover the true parameters?*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.1",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
